{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13426353,"sourceType":"datasetVersion","datasetId":8521824}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip show tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:06:06.697440Z","iopub.execute_input":"2025-10-19T19:06:06.698120Z","iopub.status.idle":"2025-10-19T19:06:08.954487Z","shell.execute_reply.started":"2025-10-19T19:06:06.698091Z","shell.execute_reply":"2025-10-19T19:06:08.953470Z"}},"outputs":[{"name":"stdout","text":"Name: tensorflow\nVersion: 2.18.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\nRequired-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import os\nimport shutil\nimport soundfile as sf\nfrom pathlib import Path\n\n# --- Configuration ---\n# 1. Set the path to your main dataset directory\ninput_root_dir = \"/kaggle/input/cleaned-audio-milan/LibriSpeech/train-clean-100/\"\n\n# 2. Set the path where you want to save the new dataset\noutput_root_dir = \"/kaggle/working/LibriSpeech-WAV-Complete/\"\n# ---\n\nprint(f\"Starting transfer and conversion from '{input_root_dir}'...\")\nprint(f\"Output will be saved in '{output_root_dir}'.\")\n\n# Walk through the entire directory structure\nfor dirpath, _, filenames in os.walk(input_root_dir):\n    for filename in filenames:\n        # Construct the full path to the source file\n        input_file_path = os.path.join(dirpath, filename)\n        \n        # Create the corresponding output directory structure\n        relative_path = os.path.relpath(dirpath, input_root_dir)\n        output_dir = os.path.join(output_root_dir, relative_path)\n        os.makedirs(output_dir, exist_ok=True)\n\n        # --- Logic to either convert or copy the file ---\n        try:\n            if filename.endswith(\".flac\"):\n                # It's an audio file, so convert it to WAV\n                \n                # Create the full path for the output WAV file\n                wav_filename = Path(filename).stem + \".wav\"\n                output_file_path = os.path.join(output_dir, wav_filename)\n\n                # Read the FLAC data and write it as WAV\n                audio_data, sample_rate = sf.read(input_file_path)\n                sf.write(output_file_path, audio_data, sample_rate)\n\n            else:\n                # It's a non-audio file (e.g., .txt), so copy it directly\n                \n                # Construct the output path\n                output_file_path = os.path.join(output_dir, filename)\n                \n                # Use shutil.copy2 to preserve file metadata\n                shutil.copy2(input_file_path, output_file_path)\n\n        except Exception as e:\n            print(f\"Error processing {input_file_path}: {e}\")\n\nprint(\"\\n--- Process Complete ---\")\nprint(f\"New dataset is ready at: '{output_root_dir}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:06:08.956392Z","iopub.execute_input":"2025-10-19T19:06:08.956991Z","iopub.status.idle":"2025-10-19T19:06:19.915904Z","shell.execute_reply.started":"2025-10-19T19:06:08.956955Z","shell.execute_reply":"2025-10-19T19:06:19.914529Z"}},"outputs":[{"name":"stdout","text":"Starting transfer and conversion from '/kaggle/input/cleaned-audio-milan/LibriSpeech/train-clean-100/'...\nOutput will be saved in '/kaggle/working/LibriSpeech-WAV-Complete/'.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_561/2449311407.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# Read the FLAC data and write it as WAV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m     with SoundFile(file, 'r', samplerate, channels,\n\u001b[0m\u001b[1;32m    306\u001b[0m                    subtype, endian, format, closefd) as f:\n\u001b[1;32m    307\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":51},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport librosa\nimport soundfile as sf\nimport os\nimport matplotlib.pyplot as plt\n# --- 1. Configuration ---\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nTraining_dirs=\"/kaggle/working/LibriSpeech-WAV-Complete/\"\n# Parameters\nSAMPLE_RATE = 16000\nBATCH_SIZE = 32\nEPOCHS = 15 # Set to a higher number for real training\n\n# Create a dummy vocabulary with only uppercase letters and apostrophe\nCHARACTERS = [\n    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n    \"'\",' ']\n\n# Create character-to-number mappings\nchar_to_num = tf.keras.layers.StringLookup(vocabulary=list(CHARACTERS), mask_token=None)\nnum_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\nVOCAB_SIZE = char_to_num.vocabulary_size()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:06:28.689528Z","iopub.execute_input":"2025-10-19T19:06:28.690225Z","iopub.status.idle":"2025-10-19T19:06:28.711751Z","shell.execute_reply.started":"2025-10-19T19:06:28.690200Z","shell.execute_reply":"2025-10-19T19:06:28.710983Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Function to create dummy data\ndef load_data():\n    file_paths = []\n    transcriptions = []\n    directories=[]\n    label_files=[]\n    for lfold1 in os.listdir(Training_dirs):\n        for lfold2 in os.listdir(os.path.join(Training_dirs,lfold1)):\n            full_path = os.path.join(Training_dirs, lfold1,lfold2)\n            if os.path.isdir(full_path):\n                directories.append(full_path)\n                label_files.append(os.path.join(Training_dirs, lfold1,lfold2,lfold1+'-'+lfold2+'.trans.txt'))\n    for label_path in label_files:\n        with open(label_path,'r') as labels:\n            for line in labels.readlines():\n                transcriptions.append(line.split(' ',maxsplit=1)[1].strip())\n    for path in directories:\n        fp=[]\n        for file in os.listdir(path):\n            if(file.endswith('.wav')):\n                fp.append(os.path.join(path,file))\n        fp.sort()\n        file_paths+=fp\n    \n    print(len(label_files))\n        \n    return file_paths, transcriptions\n#load_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:06:28.713298Z","iopub.execute_input":"2025-10-19T19:06:28.714011Z","iopub.status.idle":"2025-10-19T19:06:28.720483Z","shell.execute_reply.started":"2025-10-19T19:06:28.713980Z","shell.execute_reply":"2025-10-19T19:06:28.719826Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# --- 2. tf.data Pipeline (No Augmentation) ---\n\ndef preprocess_audio(file_path):\n    \"\"\"Loads and converts a FLAC file to a log Mel spectrogram.\"\"\"\n    try:\n        path_str = file_path.numpy().decode('utf-8')\n        y, sr = librosa.load(path_str, sr=SAMPLE_RATE)\n        \n        # Compute the Mel spectrogram\n        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n        \n        # Convert to log scale (decibels)\n        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n        \n        # Add a channel dimension\n        log_mel_spec = np.expand_dims(log_mel_spec.T, axis=-1)\n        \n        return log_mel_spec.astype(np.float32)\n    except Exception as e:\n        print(f\"Error processing file {file_path.numpy()}: {e}\")\n        os.exit()\n        return np.zeros((100, 80, 1), dtype=np.float32)\n       \n\nSAMPLE_RATE = 16000\nN_FFT = 400\nHOP_LENGTH = 160\nN_MELS = 80\n\ndef power_to_db(S, ref=1.0, top_db=80.0):\n    \"\"\"Converts a power spectrogram to the decibel scale.\"\"\"\n    log_spec = 10.0 * (tf.math.log(tf.maximum(S, 1e-10)) / tf.math.log(10.0))\n    log_spec -= 10.0 * (tf.math.log(tf.maximum(ref, 1e-10)) / tf.math.log(10.0))\n    return tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n\n@tf.function\ndef preprocess_audio_tf(file_path: tf.Tensor):\n    \"\"\"\n    Loads and converts a FLAC file to a log Mel spectrogram using TensorFlow,\n    with padding to match librosa's default behavior.\n    \"\"\"\n    try:\n        \n        audio_binary = tf.io.read_file(file_path)\n    \n        # decode_wav returns a normalized float32 tensor and the sample rate.\n        # desired_channels=1 ensures the audio is mono.\n        audio_tensor, _ = tf.audio.decode_wav(audio_binary, desired_channels=1)\n    \n        # Squeeze the channel dimension, leaving a 1D waveform.\n        # NO further normalization is needed.\n        waveform = tf.squeeze(audio_tensor, axis=-1)\n\n        # --- FIX: Manually pad the waveform to match librosa ---\n        # (The rest of your function remains the same and is correct)\n        padding = N_FFT // 2\n        waveform = tf.pad(waveform, [[padding, padding]], mode=\"REFLECT\")\n        \n        # --- 2. Compute the STFT (The rest is the same) ---\n        stft = tf.signal.stft(\n            waveform,\n            frame_length=N_FFT,\n            frame_step=HOP_LENGTH,\n            fft_length=N_FFT\n        )\n        spectrogram = tf.abs(stft)\n\n        # ... (rest of the function is identical) ...\n        power_spectrogram = spectrogram ** 2\n        num_spectrogram_bins = stft.shape[-1]\n        mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n            num_mel_bins=N_MELS,\n            num_spectrogram_bins=num_spectrogram_bins,\n            sample_rate=SAMPLE_RATE,\n            lower_edge_hertz=20.0,\n            upper_edge_hertz=8000.0\n        )\n        mel_spectrogram = tf.tensordot(power_spectrogram, mel_filterbank, 1)\n        log_mel_spectrogram = power_to_db(mel_spectrogram)\n        log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, axis=-1)\n\n        return tf.cast(log_mel_spectrogram, dtype=tf.float32)\n\n    except Exception as e:\n        tf.print(\"Error processing file:\", file_path, \"Exception:\", e, summarize=-1)\n        return tf.zeros((100, N_MELS, 1), dtype=tf.float32)\n    \ndef preprocess_label(text_label):\n    \"\"\"Converts a text string to an integer sequence, ensuring it's uppercase.\"\"\"\n    # Convert all characters to uppercase to match the vocabulary\n    text_tensor = tf.strings.upper(text_label)\n    chars = tf.strings.unicode_split(text_tensor, input_encoding=\"UTF-8\")\n    return char_to_num(chars)\n# (Keep all your other functions like preprocess_audio_tf_flac, preprocess_label, etc.)\n\n@tf.function\ndef preprocess_and_filter(path, label):\n    \"\"\"\n    Applies full preprocessing to audio and text, and returns their lengths.\n    \"\"\"\n    # Process the audio file to get the final spectrogram\n    spectrogram = preprocess_audio_tf(path)\n    \n    # Process the text label to get the integer tokens\n    processed_label = preprocess_label(label)\n\n    # Get the number of time steps from the spectrogram\n    spectrogram_length = tf.shape(spectrogram)[0]\n    \n    # Get the number of characters/tokens from the label\n    label_length = tf.shape(processed_label)[0]\n\n    return spectrogram, processed_label, spectrogram_length, label_length\n#preprocess_audio_tf(\"/kaggle/working/LibriSpeech-WAV-Complete/1081/125237/1081-125237-0035.wav\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:06:28.721198Z","iopub.execute_input":"2025-10-19T19:06:28.721444Z","iopub.status.idle":"2025-10-19T19:06:28.744372Z","shell.execute_reply.started":"2025-10-19T19:06:28.721426Z","shell.execute_reply":"2025-10-19T19:06:28.743708Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"'''def build_pipeline(paths, labels, is_training=False):\n    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n    \n    ds = tf.data.Dataset.zip((path_ds, label_ds))\n    if is_training:\n        ds = ds.shuffle(buffer_size=len(paths))\n    \n    # Map preprocessing functions\n    ds = ds.map(\n        lambda path, label: (\n            tf.py_function(preprocess_audio, [path], tf.float32),\n            preprocess_label(label)\n        ),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    # Batch and pad\n    ds = ds.padded_batch(\n        batch_size=BATCH_SIZE,\n        padded_shapes=([None, 80, 1], [None]),\n        padding_values=(0.0, tf.cast(char_to_num.vocabulary_size(), dtype=tf.int64)+1)\n    )\n    \n    # Prefetch for performance\n    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return ds'''\n\ndef build_pipeline(paths, labels, is_training=False):\n    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n    \n    ds = tf.data.Dataset.zip((path_ds, label_ds))\n    if is_training:\n        ds = ds.shuffle(buffer_size=len(paths))\n    \n    # 1. Map the combined preprocessing and length calculation function\n    ds = ds.map(preprocess_and_filter, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    # 2. Filter out items where the spectrogram is shorter than the label\n    ds = ds.filter(\n        lambda spectrogram, label, spec_len, label_len: spec_len >= label_len\n    )\n    \n    # 3. Remove the lengths from the dataset, keeping only spectrogram and label\n    ds = ds.map(\n        lambda spectrogram, label, spec_len, label_len: (spectrogram, label),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    # 4. Batch and pad as before\n    ds = ds.padded_batch(\n        batch_size=BATCH_SIZE,\n        padded_shapes=([None, 80, 1], [None]),\n        padding_values=(0.0, tf.cast(0, dtype=tf.int64))\n    )\n    \n    # Prefetch for performance\n    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:06:28.808934Z","iopub.execute_input":"2025-10-19T19:06:28.809637Z","iopub.status.idle":"2025-10-19T19:06:28.816166Z","shell.execute_reply.started":"2025-10-19T19:06:28.809613Z","shell.execute_reply":"2025-10-19T19:06:28.815278Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"def build_model(input_shape, vocab_size):\n    \"\"\"Builds a deeper, more regularized CNN-RNN model.\"\"\"\n    inputs = tf.keras.Input(shape=input_shape, name=\"input_spectrogram\")\n\n    # Make the CNN frontend deeper\n    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x) # <-- Add SpatialDropout\n    \n    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x) # <-- Add SpatialDropout\n\n    # Reshape for the RNN\n    _, time_dim, freq_dim, channel_dim = x.shape\n    new_feature_dim = freq_dim * channel_dim\n    x = tf.keras.layers.Reshape((time_dim, new_feature_dim))(x)\n    \n    # Make the RNN backend deeper and with stronger dropout\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n    x = tf.keras.layers.Dropout(0.4)(x) # <-- Increased Dropout\n    x = tf.keras.layers.BatchNormalization()(x)\n    \n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n    x = tf.keras.layers.Dropout(0.4)(x) # <-- Increased Dropout\n    x = tf.keras.layers.BatchNormalization()(x)\n    \n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n    x = tf.keras.layers.Dropout(0.4)(x) # <-- Increased Dropout\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    # Output layer\n    outputs = tf.keras.layers.Dense(units=vocab_size + 1, activation=\"softmax\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model\n\n# --- 3. Model Definition and CTC Loss ---\n\n\"\"\"older model, has less layers but is proven to underfit given the data.\"\"\"\ndef build_model_old1(input_shape, vocab_size):\n    \"\"\"Builds a CNN-RNN model with CTC loss.\"\"\"\n    inputs = tf.keras.Input(shape=input_shape, name=\"input_spectrogram\")\n\n    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n    \n    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n\n    _, time_dim, freq_dim, channel_dim = x.shape\n    new_feature_dim = freq_dim * channel_dim\n    x = tf.keras.layers.Reshape((time_dim, new_feature_dim))(x)\n    \n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    \n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    outputs = tf.keras.layers.Dense(units=vocab_size+1, activation=\"softmax\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:24:34.026335Z","iopub.execute_input":"2025-10-19T19:24:34.026671Z","iopub.status.idle":"2025-10-19T19:24:34.038987Z","shell.execute_reply.started":"2025-10-19T19:24:34.026647Z","shell.execute_reply":"2025-10-19T19:24:34.038268Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"\ndef ctc_loss(y_true, y_pred):\n    batch_len = tf.cast(tf.shape(y_pred)[0], dtype=\"int64\")\n    time_steps = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n\n    input_length = time_steps * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n    \n    # Compute actual label lengths\n    label_length = tf.math.count_nonzero(y_true, axis=1, keepdims=True)\n    label_length = tf.cast(label_length, dtype=\"int64\")\n    #label_length = tf.minimum(label_length, input_length)\n    \n    loss = tf.keras.backend.ctc_batch_cost(\n        y_true,\n        y_pred,\n        input_length,\n        label_length,\n    )\n\n\n    return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:06:28.835041Z","iopub.execute_input":"2025-10-19T19:06:28.835259Z","iopub.status.idle":"2025-10-19T19:06:28.851013Z","shell.execute_reply.started":"2025-10-19T19:06:28.835242Z","shell.execute_reply":"2025-10-19T19:06:28.850375Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# --- 4. Main Training and Saving Logic ---\n\nif __name__ == \"__main__\":\n    # Generate the dataset\n    paths, labels = load_data()\n    \n    # Split data (simple split for demonstration)\n    split_idx = int(len(paths) * 0.9)\n    train_paths, val_paths = paths[:split_idx], paths[split_idx:]\n    train_labels, val_labels = labels[:split_idx], labels[split_idx:]\n    \n    # Build data pipelines\n    train_ds = build_pipeline(train_paths, train_labels, is_training=True)\n    val_ds = build_pipeline(val_paths, val_labels, is_training=False)\n    \n    steps_per_epoch = len(train_paths) // BATCH_SIZE\n    total_decay_steps = steps_per_epoch * EPOCHS\n    \n    cosine_schedule = tf.keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate=1e-2,  # The starting learning rate\n        decay_steps=total_decay_steps, # The number of steps to decay over\n        alpha=0 # The minimum learning rate as a fraction of the initial rate\n    )\n    Optimizer = tf.keras.optimizers.Adam(learning_rate=cosine_schedule)\n    # Build the model\n    # We don't know the exact input shape, so we use None for the time dimension\n    model = build_model(input_shape=(None, 80, 1), vocab_size=VOCAB_SIZE)\n    model.compile(optimizer=\"adam\", loss=ctc_loss)\n    \n    model.summary()\n    for x_batch, y_batch in train_ds.take(1):\n        preds = model(x_batch)\n        print(\"Model output time steps:\", preds.shape[1])\n        print(\"Max label length in batch:\", tf.reduce_max(tf.math.count_nonzero(y_batch, axis=1)))\n\n    # Set up callbacks\n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=\"asr_model_best.keras\",\n        save_best_only=True,\n        monitor=\"val_loss\",\n        verbose=1\n    )\n    # Train the model\n    print(\"\\n--- Starting Model Training ---\")\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS,\n        callbacks=[model_checkpoint]\n    )\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:24:40.639197Z","iopub.execute_input":"2025-10-19T19:24:40.639501Z","iopub.status.idle":"2025-10-19T21:44:49.866558Z","shell.execute_reply.started":"2025-10-19T19:24:40.639478Z","shell.execute_reply":"2025-10-19T21:44:49.865857Z"}},"outputs":[{"name":"stdout","text":"585\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_10\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_spectrogram (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cast_5 (\u001b[38;5;33mCast\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_54          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_55          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ spatial_dropout2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_56          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_57          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ spatial_dropout2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_10 (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_25                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,147,776\u001b[0m │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_58          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_26                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,574,912\u001b[0m │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_59          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_27                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,574,912\u001b[0m │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_60          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)       │        \u001b[38;5;34m15,390\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_spectrogram (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cast_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_54          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_55          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ spatial_dropout2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_56          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_57          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ spatial_dropout2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_25                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,147,776</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_58          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_26                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_59          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_27                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_60          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,390</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,384,894\u001b[0m (24.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,384,894</span> (24.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,381,438\u001b[0m (24.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,381,438</span> (24.34 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,456\u001b[0m (13.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> (13.50 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Model output time steps: 412\nMax label length in batch: tf.Tensor(282, shape=(), dtype=int64)\n\n--- Starting Model Training ---\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1760901895.904535     561 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_10_1/spatial_dropout2d_2_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"    803/Unknown \u001b[1m551s\u001b[0m 670ms/step - loss: 557.3900\nEpoch 1: val_loss improved from inf to 284.41974, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 707ms/step - loss: 557.2278 - val_loss: 284.4197\nEpoch 2/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - loss: 268.3391\nEpoch 2: val_loss improved from 284.41974 to 189.52693, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 701ms/step - loss: 268.3128 - val_loss: 189.5269\nEpoch 3/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - loss: 203.6213\nEpoch 3: val_loss improved from 189.52693 to 157.79767, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 700ms/step - loss: 203.6121 - val_loss: 157.7977\nEpoch 4/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - loss: 172.3438\nEpoch 4: val_loss improved from 157.79767 to 138.30461, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 696ms/step - loss: 172.3377 - val_loss: 138.3046\nEpoch 5/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - loss: 150.8970\nEpoch 5: val_loss improved from 138.30461 to 127.50397, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 695ms/step - loss: 150.8934 - val_loss: 127.5040\nEpoch 6/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - loss: 134.4951\nEpoch 6: val_loss improved from 127.50397 to 115.36959, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 695ms/step - loss: 134.4939 - val_loss: 115.3696\nEpoch 7/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step - loss: 123.6845\nEpoch 7: val_loss improved from 115.36959 to 110.11495, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 693ms/step - loss: 123.6835 - val_loss: 110.1150\nEpoch 8/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step - loss: 115.2150\nEpoch 8: val_loss improved from 110.11495 to 105.13895, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 693ms/step - loss: 115.2137 - val_loss: 105.1389\nEpoch 9/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - loss: 108.4321\nEpoch 9: val_loss improved from 105.13895 to 100.48463, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 697ms/step - loss: 108.4314 - val_loss: 100.4846\nEpoch 10/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - loss: 103.5762\nEpoch 10: val_loss improved from 100.48463 to 96.89747, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 699ms/step - loss: 103.5751 - val_loss: 96.8975\nEpoch 11/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - loss: 96.4322\nEpoch 11: val_loss improved from 96.89747 to 93.37787, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 695ms/step - loss: 96.4332 - val_loss: 93.3779\nEpoch 12/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - loss: 93.3550\nEpoch 12: val_loss improved from 93.37787 to 90.65246, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 696ms/step - loss: 93.3553 - val_loss: 90.6525\nEpoch 13/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660ms/step - loss: 90.4108\nEpoch 13: val_loss improved from 90.65246 to 88.72932, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 694ms/step - loss: 90.4107 - val_loss: 88.7293\nEpoch 14/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - loss: 87.9924\nEpoch 14: val_loss did not improve from 88.72932\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 696ms/step - loss: 87.9935 - val_loss: 89.7892\nEpoch 15/15\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658ms/step - loss: 86.1120\nEpoch 15: val_loss improved from 88.72932 to 87.93477, saving model to asr_model_best.keras\n\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 691ms/step - loss: 86.1123 - val_loss: 87.9348\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n    # Save the final model\n    model.save(\"/kaggle/working/asr_model_final_ep15.keras\")\n    print(\"\\n--- Training complete. Final model saved as asr_model_final.keras ---\")\n    print(\"Best performing model during training saved as asr_model_best.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T21:49:32.805509Z","iopub.execute_input":"2025-10-19T21:49:32.805784Z","iopub.status.idle":"2025-10-19T21:49:33.453078Z","shell.execute_reply.started":"2025-10-19T21:49:32.805765Z","shell.execute_reply":"2025-10-19T21:49:33.452272Z"}},"outputs":[{"name":"stdout","text":"\n--- Training complete. Final model saved as asr_model_final.keras ---\nBest performing model during training saved as asr_model_best.keras\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"#quantised model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T19:11:18.909098Z","iopub.status.idle":"2025-10-19T19:11:18.909417Z","shell.execute_reply.started":"2025-10-19T19:11:18.909247Z","shell.execute_reply":"2025-10-19T19:11:18.909262Z"}},"outputs":[],"execution_count":null}]}
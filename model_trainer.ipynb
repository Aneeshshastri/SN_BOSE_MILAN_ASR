{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df88359c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:32:08.929372Z",
     "iopub.status.busy": "2025-10-19T17:32:08.929116Z",
     "iopub.status.idle": "2025-10-19T17:32:11.754958Z",
     "shell.execute_reply": "2025-10-19T17:32:11.754148Z"
    },
    "papermill": {
     "duration": 2.831361,
     "end_time": "2025-10-19T17:32:11.756392",
     "exception": false,
     "start_time": "2025-10-19T17:32:08.925031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 2.18.0\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /usr/local/lib/python3.11/dist-packages\r\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\r\n",
      "Required-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\r\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce624e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:32:11.763223Z",
     "iopub.status.busy": "2025-10-19T17:32:11.762526Z",
     "iopub.status.idle": "2025-10-19T17:43:33.504881Z",
     "shell.execute_reply": "2025-10-19T17:43:33.504068Z"
    },
    "papermill": {
     "duration": 681.749124,
     "end_time": "2025-10-19T17:43:33.508347",
     "exception": false,
     "start_time": "2025-10-19T17:32:11.759223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transfer and conversion from '/kaggle/input/cleaned-audio-milan/LibriSpeech/train-clean-100/'...\n",
      "Output will be saved in '/kaggle/working/LibriSpeech-WAV-Complete/'.\n",
      "\n",
      "--- Process Complete ---\n",
      "New dataset is ready at: '/kaggle/working/LibriSpeech-WAV-Complete/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Set the path to your main dataset directory\n",
    "input_root_dir = \"/kaggle/input/cleaned-audio-milan/LibriSpeech/train-clean-100/\"\n",
    "\n",
    "# 2. Set the path where you want to save the new dataset\n",
    "output_root_dir = \"/kaggle/working/LibriSpeech-WAV-Complete/\"\n",
    "# ---\n",
    "\n",
    "print(f\"Starting transfer and conversion from '{input_root_dir}'...\")\n",
    "print(f\"Output will be saved in '{output_root_dir}'.\")\n",
    "\n",
    "# Walk through the entire directory structure\n",
    "for dirpath, _, filenames in os.walk(input_root_dir):\n",
    "    for filename in filenames:\n",
    "        # Construct the full path to the source file\n",
    "        input_file_path = os.path.join(dirpath, filename)\n",
    "        \n",
    "        # Create the corresponding output directory structure\n",
    "        relative_path = os.path.relpath(dirpath, input_root_dir)\n",
    "        output_dir = os.path.join(output_root_dir, relative_path)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # --- Logic to either convert or copy the file ---\n",
    "        try:\n",
    "            if filename.endswith(\".flac\"):\n",
    "                # It's an audio file, so convert it to WAV\n",
    "                \n",
    "                # Create the full path for the output WAV file\n",
    "                wav_filename = Path(filename).stem + \".wav\"\n",
    "                output_file_path = os.path.join(output_dir, wav_filename)\n",
    "\n",
    "                # Read the FLAC data and write it as WAV\n",
    "                audio_data, sample_rate = sf.read(input_file_path)\n",
    "                sf.write(output_file_path, audio_data, sample_rate)\n",
    "\n",
    "            else:\n",
    "                # It's a non-audio file (e.g., .txt), so copy it directly\n",
    "                \n",
    "                # Construct the output path\n",
    "                output_file_path = os.path.join(output_dir, filename)\n",
    "                \n",
    "                # Use shutil.copy2 to preserve file metadata\n",
    "                shutil.copy2(input_file_path, output_file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {input_file_path}: {e}\")\n",
    "\n",
    "print(\"\\n--- Process Complete ---\")\n",
    "print(f\"New dataset is ready at: '{output_root_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d25f121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:43:33.515042Z",
     "iopub.status.busy": "2025-10-19T17:43:33.514552Z",
     "iopub.status.idle": "2025-10-19T17:43:50.221641Z",
     "shell.execute_reply": "2025-10-19T17:43:50.220777Z"
    },
    "papermill": {
     "duration": 16.711768,
     "end_time": "2025-10-19T17:43:50.222918",
     "exception": false,
     "start_time": "2025-10-19T17:43:33.511150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 17:43:35.136689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760895815.343361      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760895815.396374      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1760895830.158447      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# --- 1. Configuration and Dummy Data Generation ---\n",
    "\n",
    "Training_dirs=\"/kaggle/working/LibriSpeech-WAV-Complete/\"\n",
    "# Parameters\n",
    "SAMPLE_RATE = 16000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15 # Set to a higher number for real training\n",
    "\n",
    "# Create a dummy vocabulary with only uppercase letters and apostrophe\n",
    "CHARACTERS = [\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    \"'\",' ']\n",
    "\n",
    "# Create character-to-number mappings\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=list(CHARACTERS), mask_token=None)\n",
    "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n",
    "VOCAB_SIZE = char_to_num.vocabulary_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be9d231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:43:50.229387Z",
     "iopub.status.busy": "2025-10-19T17:43:50.228939Z",
     "iopub.status.idle": "2025-10-19T17:43:50.235326Z",
     "shell.execute_reply": "2025-10-19T17:43:50.234744Z"
    },
    "papermill": {
     "duration": 0.010816,
     "end_time": "2025-10-19T17:43:50.236396",
     "exception": false,
     "start_time": "2025-10-19T17:43:50.225580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create dummy data\n",
    "def load_data():\n",
    "    file_paths = []\n",
    "    transcriptions = []\n",
    "    directories=[]\n",
    "    label_files=[]\n",
    "    for lfold1 in os.listdir(Training_dirs):\n",
    "        for lfold2 in os.listdir(os.path.join(Training_dirs,lfold1)):\n",
    "            full_path = os.path.join(Training_dirs, lfold1,lfold2)\n",
    "            if os.path.isdir(full_path):\n",
    "                directories.append(full_path)\n",
    "                label_files.append(os.path.join(Training_dirs, lfold1,lfold2,lfold1+'-'+lfold2+'.trans.txt'))\n",
    "    for label_path in label_files:\n",
    "        with open(label_path,'r') as labels:\n",
    "            for line in labels.readlines():\n",
    "                transcriptions.append(line.split(' ',maxsplit=1)[1].strip())\n",
    "    for path in directories:\n",
    "        fp=[]\n",
    "        for file in os.listdir(path):\n",
    "            if(file.endswith('.wav')):\n",
    "                fp.append(os.path.join(path,file))\n",
    "        fp.sort()\n",
    "        file_paths+=fp\n",
    "    \n",
    "    print(len(label_files))\n",
    "        \n",
    "    return file_paths, transcriptions\n",
    "#load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c83d3d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:43:50.242541Z",
     "iopub.status.busy": "2025-10-19T17:43:50.242315Z",
     "iopub.status.idle": "2025-10-19T17:43:50.255152Z",
     "shell.execute_reply": "2025-10-19T17:43:50.254308Z"
    },
    "papermill": {
     "duration": 0.017419,
     "end_time": "2025-10-19T17:43:50.256311",
     "exception": false,
     "start_time": "2025-10-19T17:43:50.238892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 2. tf.data Pipeline (No Augmentation) ---\n",
    "\n",
    "def preprocess_audio(file_path):\n",
    "    \"\"\"Loads and converts a FLAC file to a log Mel spectrogram.\"\"\"\n",
    "    try:\n",
    "        path_str = file_path.numpy().decode('utf-8')\n",
    "        y, sr = librosa.load(path_str, sr=SAMPLE_RATE)\n",
    "        \n",
    "        # Compute the Mel spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
    "        \n",
    "        # Convert to log scale (decibels)\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        # Add a channel dimension\n",
    "        log_mel_spec = np.expand_dims(log_mel_spec.T, axis=-1)\n",
    "        \n",
    "        return log_mel_spec.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path.numpy()}: {e}\")\n",
    "        os.exit()\n",
    "        return np.zeros((100, 80, 1), dtype=np.float32)\n",
    "       \n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = 160\n",
    "N_MELS = 80\n",
    "\n",
    "def power_to_db(S, ref=1.0, top_db=80.0):\n",
    "    \"\"\"Converts a power spectrogram to the decibel scale.\"\"\"\n",
    "    log_spec = 10.0 * (tf.math.log(tf.maximum(S, 1e-10)) / tf.math.log(10.0))\n",
    "    log_spec -= 10.0 * (tf.math.log(tf.maximum(ref, 1e-10)) / tf.math.log(10.0))\n",
    "    return tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "@tf.function\n",
    "def preprocess_audio_tf(file_path: tf.Tensor):\n",
    "    \"\"\"\n",
    "    Loads and converts a FLAC file to a log Mel spectrogram using TensorFlow,\n",
    "    with padding to match librosa's default behavior.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        audio_binary = tf.io.read_file(file_path)\n",
    "    \n",
    "        # decode_wav returns a normalized float32 tensor and the sample rate.\n",
    "        # desired_channels=1 ensures the audio is mono.\n",
    "        audio_tensor, _ = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "    \n",
    "        # Squeeze the channel dimension, leaving a 1D waveform.\n",
    "        # NO further normalization is needed.\n",
    "        waveform = tf.squeeze(audio_tensor, axis=-1)\n",
    "\n",
    "        # --- FIX: Manually pad the waveform to match librosa ---\n",
    "        # (The rest of your function remains the same and is correct)\n",
    "        padding = N_FFT // 2\n",
    "        waveform = tf.pad(waveform, [[padding, padding]], mode=\"REFLECT\")\n",
    "        \n",
    "        # --- 2. Compute the STFT (The rest is the same) ---\n",
    "        stft = tf.signal.stft(\n",
    "            waveform,\n",
    "            frame_length=N_FFT,\n",
    "            frame_step=HOP_LENGTH,\n",
    "            fft_length=N_FFT\n",
    "        )\n",
    "        spectrogram = tf.abs(stft)\n",
    "\n",
    "        # ... (rest of the function is identical) ...\n",
    "        power_spectrogram = spectrogram ** 2\n",
    "        num_spectrogram_bins = stft.shape[-1]\n",
    "        mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=N_MELS,\n",
    "            num_spectrogram_bins=num_spectrogram_bins,\n",
    "            sample_rate=SAMPLE_RATE,\n",
    "            lower_edge_hertz=20.0,\n",
    "            upper_edge_hertz=8000.0\n",
    "        )\n",
    "        mel_spectrogram = tf.tensordot(power_spectrogram, mel_filterbank, 1)\n",
    "        log_mel_spectrogram = power_to_db(mel_spectrogram)\n",
    "        log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, axis=-1)\n",
    "\n",
    "        return tf.cast(log_mel_spectrogram, dtype=tf.float32)\n",
    "\n",
    "    except Exception as e:\n",
    "        tf.print(\"Error processing file:\", file_path, \"Exception:\", e, summarize=-1)\n",
    "        return tf.zeros((100, N_MELS, 1), dtype=tf.float32)\n",
    "    \n",
    "def preprocess_label(text_label):\n",
    "    \"\"\"Converts a text string to an integer sequence, ensuring it's uppercase.\"\"\"\n",
    "    # Convert all characters to uppercase to match the vocabulary\n",
    "    text_tensor = tf.strings.upper(text_label)\n",
    "    chars = tf.strings.unicode_split(text_tensor, input_encoding=\"UTF-8\")\n",
    "    return char_to_num(chars)\n",
    "# (Keep all your other functions like preprocess_audio_tf_flac, preprocess_label, etc.)\n",
    "\n",
    "@tf.function\n",
    "def preprocess_and_filter(path, label):\n",
    "    \"\"\"\n",
    "    Applies full preprocessing to audio and text, and returns their lengths.\n",
    "    \"\"\"\n",
    "    # Process the audio file to get the final spectrogram\n",
    "    spectrogram = preprocess_audio_tf(path)\n",
    "    \n",
    "    # Process the text label to get the integer tokens\n",
    "    processed_label = preprocess_label(label)\n",
    "\n",
    "    # Get the number of time steps from the spectrogram\n",
    "    spectrogram_length = tf.shape(spectrogram)[0]\n",
    "    \n",
    "    # Get the number of characters/tokens from the label\n",
    "    label_length = tf.shape(processed_label)[0]\n",
    "\n",
    "    return spectrogram, processed_label, spectrogram_length, label_length\n",
    "#preprocess_audio_tf(\"/kaggle/working/LibriSpeech-WAV-Complete/1081/125237/1081-125237-0035.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213f210d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:43:50.262026Z",
     "iopub.status.busy": "2025-10-19T17:43:50.261757Z",
     "iopub.status.idle": "2025-10-19T17:43:50.267891Z",
     "shell.execute_reply": "2025-10-19T17:43:50.267184Z"
    },
    "papermill": {
     "duration": 0.010317,
     "end_time": "2025-10-19T17:43:50.269067",
     "exception": false,
     "start_time": "2025-10-19T17:43:50.258750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''def build_pipeline(paths, labels, is_training=False):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    \n",
    "    ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "    if is_training:\n",
    "        ds = ds.shuffle(buffer_size=len(paths))\n",
    "    \n",
    "    # Map preprocessing functions\n",
    "    ds = ds.map(\n",
    "        lambda path, label: (\n",
    "            tf.py_function(preprocess_audio, [path], tf.float32),\n",
    "            preprocess_label(label)\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    # Batch and pad\n",
    "    ds = ds.padded_batch(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        padded_shapes=([None, 80, 1], [None]),\n",
    "        padding_values=(0.0, tf.cast(char_to_num.vocabulary_size(), dtype=tf.int64)+1)\n",
    "    )\n",
    "    \n",
    "    # Prefetch for performance\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds'''\n",
    "\n",
    "def build_pipeline(paths, labels, is_training=False):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    \n",
    "    ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "    if is_training:\n",
    "        ds = ds.shuffle(buffer_size=len(paths))\n",
    "    \n",
    "    # 1. Map the combined preprocessing and length calculation function\n",
    "    ds = ds.map(preprocess_and_filter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # 2. Filter out items where the spectrogram is shorter than the label\n",
    "    ds = ds.filter(\n",
    "        lambda spectrogram, label, spec_len, label_len: spec_len >= label_len\n",
    "    )\n",
    "    \n",
    "    # 3. Remove the lengths from the dataset, keeping only spectrogram and label\n",
    "    ds = ds.map(\n",
    "        lambda spectrogram, label, spec_len, label_len: (spectrogram, label),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    # 4. Batch and pad as before\n",
    "    ds = ds.padded_batch(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        padded_shapes=([None, 80, 1], [None]),\n",
    "        padding_values=(0.0, tf.cast(0, dtype=tf.int64))\n",
    "    )\n",
    "    \n",
    "    # Prefetch for performance\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09c8f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:43:50.275144Z",
     "iopub.status.busy": "2025-10-19T17:43:50.274567Z",
     "iopub.status.idle": "2025-10-19T17:43:50.286725Z",
     "shell.execute_reply": "2025-10-19T17:43:50.285737Z"
    },
    "papermill": {
     "duration": 0.016824,
     "end_time": "2025-10-19T17:43:50.288397",
     "exception": false,
     "start_time": "2025-10-19T17:43:50.271573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 3. Model Definition and CTC Loss ---\n",
    "def build_model(input_shape, vocab_size):\n",
    "    \"\"\"Builds a deeper CNN-RNN model with more capacity.\"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape, name=\"input_spectrogram\")\n",
    "\n",
    "    # Make the CNN frontend deeper\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((1, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((1, 2))(x)\n",
    "\n",
    "    # Reshape for the RNN\n",
    "    _, time_dim, freq_dim, channel_dim = x.shape\n",
    "    new_feature_dim = freq_dim * channel_dim\n",
    "    x = tf.keras.layers.Reshape((time_dim, new_feature_dim))(x)\n",
    "    \n",
    "    # Make the RNN backend deeper and wider\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size + 1, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\"\"\"older model, has less layers but is proven to underfit given the data.\"\"\"\n",
    "def build_model_old(input_shape, vocab_size):\n",
    "    \"\"\"Builds a CNN-RNN model with CTC loss.\"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape, name=\"input_spectrogram\")\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    _, time_dim, freq_dim, channel_dim = x.shape\n",
    "    new_feature_dim = freq_dim * channel_dim\n",
    "    x = tf.keras.layers.Reshape((time_dim, new_feature_dim))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size+1, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacd5d34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:43:50.297622Z",
     "iopub.status.busy": "2025-10-19T17:43:50.296488Z",
     "iopub.status.idle": "2025-10-19T17:43:50.302338Z",
     "shell.execute_reply": "2025-10-19T17:43:50.301469Z"
    },
    "papermill": {
     "duration": 0.012504,
     "end_time": "2025-10-19T17:43:50.304044",
     "exception": false,
     "start_time": "2025-10-19T17:43:50.291540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def ctc_loss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_pred)[0], dtype=\"int64\")\n",
    "    time_steps = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = time_steps * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    \n",
    "    # Compute actual label lengths\n",
    "    label_length = tf.math.count_nonzero(y_true, axis=1, keepdims=True)\n",
    "    label_length = tf.cast(label_length, dtype=\"int64\")\n",
    "    #label_length = tf.minimum(label_length, input_length)\n",
    "    \n",
    "    loss = tf.keras.backend.ctc_batch_cost(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        input_length,\n",
    "        label_length,\n",
    "    )\n",
    "\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ccc69f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:43:50.313317Z",
     "iopub.status.busy": "2025-10-19T17:43:50.313110Z",
     "iopub.status.idle": "2025-10-20T01:35:47.472132Z",
     "shell.execute_reply": "2025-10-20T01:35:47.471330Z"
    },
    "papermill": {
     "duration": 28317.21716,
     "end_time": "2025-10-20T01:35:47.525042",
     "exception": false,
     "start_time": "2025-10-19T17:43:50.307882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_spectrogram (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,147,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_spectrogram (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,147,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)       │        \u001b[38;5;34m15,390\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,384,894</span> (24.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,384,894\u001b[0m (24.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,381,438</span> (24.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,381,438\u001b[0m (24.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> (13.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,456\u001b[0m (13.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760895833.904165      19 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output time steps: 1584\n",
      "Max label length in batch: tf.Tensor(297, shape=(), dtype=int64)\n",
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/15\n",
      "    803/Unknown \u001b[1m2536s\u001b[0m 3s/step - loss: 662.3807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 388.34329, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2667s\u001b[0m 3s/step - loss: 662.2391 - val_loss: 388.3433\n",
      "Epoch 2/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 331.8370\n",
      "Epoch 2: val_loss improved from 388.34329 to 204.01157, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1869s\u001b[0m 2s/step - loss: 331.7814 - val_loss: 204.0116\n",
      "Epoch 3/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 227.0475\n",
      "Epoch 3: val_loss improved from 204.01157 to 169.81732, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1858s\u001b[0m 2s/step - loss: 227.0278 - val_loss: 169.8173\n",
      "Epoch 4/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 181.1559\n",
      "Epoch 4: val_loss improved from 169.81732 to 148.83733, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1852s\u001b[0m 2s/step - loss: 181.1486 - val_loss: 148.8373\n",
      "Epoch 5/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 163.7147\n",
      "Epoch 5: val_loss improved from 148.83733 to 135.66795, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1853s\u001b[0m 2s/step - loss: 163.7079 - val_loss: 135.6680\n",
      "Epoch 6/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 148.9128\n",
      "Epoch 6: val_loss did not improve from 135.66795\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1842s\u001b[0m 2s/step - loss: 148.9360 - val_loss: 166.6023\n",
      "Epoch 7/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 157.6610\n",
      "Epoch 7: val_loss improved from 135.66795 to 112.46395, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1828s\u001b[0m 2s/step - loss: 157.6438 - val_loss: 112.4640\n",
      "Epoch 8/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 121.6441\n",
      "Epoch 8: val_loss improved from 112.46395 to 102.35434, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1843s\u001b[0m 2s/step - loss: 121.6404 - val_loss: 102.3543\n",
      "Epoch 9/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 111.0725\n",
      "Epoch 9: val_loss improved from 102.35434 to 99.09906, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1815s\u001b[0m 2s/step - loss: 111.0719 - val_loss: 99.0991\n",
      "Epoch 10/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 101.8197\n",
      "Epoch 10: val_loss improved from 99.09906 to 90.55159, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1815s\u001b[0m 2s/step - loss: 101.8182 - val_loss: 90.5516\n",
      "Epoch 11/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 94.3169\n",
      "Epoch 11: val_loss improved from 90.55159 to 86.02840, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1815s\u001b[0m 2s/step - loss: 94.3160 - val_loss: 86.0284\n",
      "Epoch 12/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 88.7803\n",
      "Epoch 12: val_loss improved from 86.02840 to 83.10954, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1820s\u001b[0m 2s/step - loss: 88.7794 - val_loss: 83.1095\n",
      "Epoch 13/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 84.8977\n",
      "Epoch 13: val_loss improved from 83.10954 to 82.23731, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1809s\u001b[0m 2s/step - loss: 84.8972 - val_loss: 82.2373\n",
      "Epoch 14/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 82.4938\n",
      "Epoch 14: val_loss improved from 82.23731 to 81.71872, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1814s\u001b[0m 2s/step - loss: 82.4934 - val_loss: 81.7187\n",
      "Epoch 15/15\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 81.7566\n",
      "Epoch 15: val_loss improved from 81.71872 to 81.42832, saving model to asr_model_best.keras\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1810s\u001b[0m 2s/step - loss: 81.7559 - val_loss: 81.4283\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Main Training and Saving Logic ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate the dataset\n",
    "    paths, labels = load_data()\n",
    "    \n",
    "    # Split data (simple split for demonstration)\n",
    "    split_idx = int(len(paths) * 0.9)\n",
    "    train_paths, val_paths = paths[:split_idx], paths[split_idx:]\n",
    "    train_labels, val_labels = labels[:split_idx], labels[split_idx:]\n",
    "    \n",
    "    # Build data pipelines\n",
    "    train_ds = build_pipeline(train_paths, train_labels, is_training=True)\n",
    "    val_ds = build_pipeline(val_paths, val_labels, is_training=False)\n",
    "    \n",
    "    steps_per_epoch = len(train_paths) // BATCH_SIZE\n",
    "    total_decay_steps = steps_per_epoch * EPOCHS\n",
    "    \n",
    "    cosine_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=1e-3,  # The starting learning rate\n",
    "        decay_steps=total_decay_steps, # The number of steps to decay over\n",
    "        alpha=0.001 # The minimum learning rate as a fraction of the initial rate\n",
    "    )\n",
    "    Optimizer = tf.keras.optimizers.Adam(learning_rate=cosine_schedule)\n",
    "    # Build the model\n",
    "    # We don't know the exact input shape, so we use None for the time dimension\n",
    "    model = build_model(input_shape=(None, 80, 1), vocab_size=VOCAB_SIZE)\n",
    "    model.compile(optimizer=Optimizer, loss=ctc_loss)\n",
    "    \n",
    "    model.summary()\n",
    "    for x_batch, y_batch in train_ds.take(1):\n",
    "        preds = model(x_batch)\n",
    "        print(\"Model output time steps:\", preds.shape[1])\n",
    "        print(\"Max label length in batch:\", tf.reduce_max(tf.math.count_nonzero(y_batch, axis=1)))\n",
    "\n",
    "    # Set up callbacks\n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"asr_model_best.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1\n",
    "    )\n",
    "    # Train the model\n",
    "    print(\"\\n--- Starting Model Training ---\")\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[model_checkpoint]\n",
    "    )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50078279",
   "metadata": {
    "papermill": {
     "duration": 0.490075,
     "end_time": "2025-10-20T01:35:48.517249",
     "exception": false,
     "start_time": "2025-10-20T01:35:48.027174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9675de93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T01:35:49.609519Z",
     "iopub.status.busy": "2025-10-20T01:35:49.609242Z",
     "iopub.status.idle": "2025-10-20T01:35:49.985236Z",
     "shell.execute_reply": "2025-10-20T01:35:49.984513Z"
    },
    "papermill": {
     "duration": 0.880362,
     "end_time": "2025-10-20T01:35:49.986407",
     "exception": false,
     "start_time": "2025-10-20T01:35:49.106045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training complete. Final model saved as asr_model_final.keras ---\n",
      "Best performing model during training saved as asr_model_best.keras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Save the final model\n",
    "    model.save(\"asr_model_final.keras\")\n",
    "    print(\"\\n--- Training complete. Final model saved as asr_model_final.keras ---\")\n",
    "    print(\"Best performing model during training saved as asr_model_best.keras\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8521824,
     "sourceId": 13426353,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29028.942129,
   "end_time": "2025-10-20T01:35:54.261199",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-19T17:32:05.319070",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

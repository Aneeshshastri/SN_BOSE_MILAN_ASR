{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpdihsPJWsJdsCjDjUvmC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aneeshshastri/SN_BOSE_MILAN_ASR/blob/main/Train_Quartznet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers datasets accelerate audiomentations librosa==0.10.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYTLPE6Os0Xk",
        "outputId": "da57b393-89ee-4f0c-eda1-bce64c06f229"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.43.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting librosa==0.10.1\n",
            "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (4.15.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
            "  Downloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
            "  Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting python-stretch<1,>=0.3.1 (from audiomentations)\n",
            "  Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa==0.10.1)\n",
            "  Downloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa==0.10.1) (0.43.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (2.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.0->librosa==0.10.1) (4.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.1) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiomentations-0.43.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18 kB)\n",
            "Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.5/248.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: soxr, python-stretch, numpy-rms, numpy-minmax, librosa, audiomentations\n",
            "  Attempting uninstall: soxr\n",
            "    Found existing installation: soxr 1.0.0\n",
            "    Uninstalling soxr-1.0.0:\n",
            "      Successfully uninstalled soxr-1.0.0\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.11.0\n",
            "    Uninstalling librosa-0.11.0:\n",
            "      Successfully uninstalled librosa-0.11.0\n",
            "Successfully installed audiomentations-0.43.1 librosa-0.10.1 numpy-minmax-0.5.0 numpy-rms-0.6.0 python-stretch-0.3.1 soxr-0.5.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"Please upload the kaggle.json file you downloaded from your Kaggle account:\")\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "xXzxpzq9s9nn",
        "outputId": "0279e62d-92eb-42de-aa8c-347cb8ca7d1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the kaggle.json file you downloaded from your Kaggle account:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-77f4a5c2-efed-4e4d-bca0-3da8b46a6c8c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-77f4a5c2-efed-4e4d-bca0-3da8b46a6c8c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aneeshshastri\",\"key\":\"fee44b7bbfbefd812576ba350f4c6d1b\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the .kaggle directory and move the file there\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set the file permissions to be readable only by you\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vTSwf1k8s-ap"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3c7wpSgtFqp",
        "outputId": "59584071-bce0-478b-f030-41b4fc7e2872"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory for the dataset\n",
        "!mkdir -p /content/dataset\n",
        "\n",
        "# Download the dataset into the created directory\n",
        "!kaggle datasets download -d aneeshshastri/cleaned-audio-milan -p /content/dataset/\n",
        "\n",
        "!unzip /content/dataset/cleaned-audio-milan.zip -d /content/dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX_SbNrotMZC",
        "outputId": "ab877c23-6ecf-40f3-edfd-9c9405095ccc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aneeshshastri/cleaned-audio-milan\n",
            "License(s): unknown\n",
            "^C\n",
            "unzip:  cannot find or open /content/dataset/cleaned-audio-milan.zip, /content/dataset/cleaned-audio-milan.zip.zip or /content/dataset/cleaned-audio-milan.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rEA6am0sTDJ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install necessary libraries\n",
        "# Step 2: Import all required modules\n",
        "import os\n",
        "import random\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset, Audio, Dataset\n",
        "from transformers import AutoProcessor, AutoModelForCTC, TrainingArguments, Trainer\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Union\n",
        "from scipy.signal import butter, lfilter\n",
        "from audiomentations import AddGaussianNoise\n",
        "\n",
        "# Step 3: Include your full Augmenter class\n",
        "class Augmenter:\n",
        "    def __init__(self, sr=16000,\n",
        "                 noise_prob=0.3, noise_max_amp=0.01,\n",
        "                 reverb_prob=0.3, reverb_delay=0.025, reverb_decay=0.2,\n",
        "                 shuffle_prob=0.05, time_stretch_prob=0.3, time_stretch_range=(0.9, 1.1),\n",
        "                 gaps_prob=0.1, gaps_n=4, gaps_max_duration=0.1,\n",
        "                 freq_mask_prob=0.3, freq_mask_n=1):\n",
        "\n",
        "        self.sr = sr\n",
        "        self.noise_aug = AddGaussianNoise(p=1.0, max_amplitude=noise_max_amp, sample_rate=sr)\n",
        "        self.noise_prob = noise_prob\n",
        "        self.reverb_prob = reverb_prob\n",
        "        self.reverb_delay = reverb_delay\n",
        "        self.reverb_decay = reverb_decay\n",
        "        self.shuffle_prob = shuffle_prob\n",
        "        self.time_stretch_prob = time_stretch_prob\n",
        "        self.time_stretch_range = time_stretch_range\n",
        "        self.gaps_prob = gaps_prob\n",
        "        self.gaps_n = gaps_n\n",
        "        self.gaps_max_duration = gaps_max_duration\n",
        "        self.freq_mask_prob = freq_mask_prob\n",
        "        self.freq_mask_n = freq_mask_n\n",
        "\n",
        "    def augment(self, audio):\n",
        "        distortions = []\n",
        "        if random.random() < self.noise_prob: distortions.append('noise')\n",
        "        if random.random() < self.reverb_prob: distortions.append('reverb')\n",
        "        if random.random() < self.shuffle_prob: distortions.append('shuffle')\n",
        "        if random.random() < self.time_stretch_prob: distortions.append('time_stretch')\n",
        "        if random.random() < self.gaps_prob: distortions.append('missing_gaps')\n",
        "        if random.random() < self.freq_mask_prob: distortions.append('frequency_masking')\n",
        "\n",
        "        # Make sure audio is a numpy array for processing\n",
        "        audio = np.array(audio, dtype=np.float32)\n",
        "\n",
        "        for distortion in distortions:\n",
        "            if distortion == 'noise': audio = self._add_noise(audio)\n",
        "            elif distortion == 'reverb': audio = self._add_reverb(audio)\n",
        "            elif distortion == 'shuffle': audio = self._segment_shuffle(audio)\n",
        "            elif distortion == 'time_stretch': audio = self._time_stretch(audio)\n",
        "            elif distortion == 'missing_gaps': audio = self._add_missing_gaps(audio)\n",
        "            elif distortion == 'frequency_masking': audio = self._add_frequency_mask(audio)\n",
        "        return audio\n",
        "\n",
        "    def _add_noise(self, audio):\n",
        "        return self.noise_aug(samples=audio, sample_rate=self.sr)\n",
        "\n",
        "    def _add_reverb(self, audio):\n",
        "        delay = int(self.reverb_delay * self.sr)\n",
        "        reverb = np.pad(audio * self.reverb_decay, (delay, 0), 'constant')\n",
        "        if len(reverb) > len(audio):\n",
        "            reverb = reverb[:len(audio)]\n",
        "        return audio + reverb\n",
        "\n",
        "    def _segment_shuffle(self, audio):\n",
        "        # Using a simple and effective shuffle\n",
        "        segments = np.array_split(audio, 3)\n",
        "        random.shuffle(segments)\n",
        "        return np.concatenate(segments)\n",
        "\n",
        "    def _time_stretch(self, audio):\n",
        "        return librosa.effects.time_stretch(y=audio, rate=random.uniform(*self.time_stretch_range))\n",
        "\n",
        "    def _add_missing_gaps(self, audio):\n",
        "        gap_audio = np.copy(audio)\n",
        "        for _ in range(self.gaps_n):\n",
        "            gap_duration = random.uniform(0.1, self.gaps_max_duration)\n",
        "            gap_samples = int(gap_duration * self.sr)\n",
        "            if len(gap_audio) > gap_samples:\n",
        "                start = random.randint(0, len(gap_audio) - gap_samples)\n",
        "                gap_audio[start:start + gap_samples] = 0\n",
        "        return gap_audio\n",
        "\n",
        "    def _add_frequency_mask(self, audio):\n",
        "        masked_audio = np.copy(audio)\n",
        "        nyquist = self.sr / 2\n",
        "        for _ in range(self.freq_mask_n):\n",
        "            l_freq = random.uniform(500, 5000)\n",
        "            h_freq = l_freq + random.uniform(500, 2000)\n",
        "            if h_freq >= nyquist: continue\n",
        "            b, a = butter(N=4, Wn=[l_freq, h_freq], btype=\"bandstop\", fs=self.sr)\n",
        "            masked_audio = lfilter(b, a, masked_audio)\n",
        "        return masked_audio\n",
        "\n",
        "# Step 4: Your custom load_data function\n",
        "Training_dirs = \"/content/dataset/LibriSpeech/train-clean-100/\"\n",
        "\n",
        "def load_data():\n",
        "    file_paths = []\n",
        "    transcriptions = []\n",
        "    # Simplified loop for clarity\n",
        "    for speaker_id in os.listdir(Training_dirs):\n",
        "        speaker_path = os.path.join(Training_dirs, speaker_id)\n",
        "        if not os.path.isdir(speaker_path): continue\n",
        "        for chapter_id in os.listdir(speaker_path):\n",
        "            chapter_path = os.path.join(speaker_path, chapter_id)\n",
        "            if not os.path.isdir(chapter_path): continue\n",
        "\n",
        "            trans_file = f\"{speaker_id}-{chapter_id}.trans.txt\"\n",
        "            trans_path = os.path.join(chapter_path, trans_file)\n",
        "\n",
        "            if os.path.exists(trans_path):\n",
        "                with open(trans_path, 'r') as f:\n",
        "                    for line in f:\n",
        "                        parts = line.strip().split(' ', 1)\n",
        "                        file_id = parts[0]\n",
        "                        text = parts[1]\n",
        "\n",
        "                        audio_path = os.path.join(chapter_path, f\"{file_id}.flac\")\n",
        "                        if os.path.exists(audio_path):\n",
        "                            file_paths.append(audio_path)\n",
        "                            transcriptions.append(text)\n",
        "    return file_paths, transcriptions\n",
        "\n",
        "# Step 5: Execute the pipeline\n",
        "print(\"Loading data using custom function...\")\n",
        "file_paths, transcriptions = load_data()\n",
        "\n",
        "# Create a dictionary for our data\n",
        "data_dict = {\"file_path\": file_paths, \"transcription\": transcriptions}\n",
        "\n",
        "# Bridge the gap: Convert your lists into a Hugging Face Dataset object\n",
        "hf_dataset = Dataset.from_dict(data_dict)\n",
        "\n",
        "print(f\"\\nCreated a dataset with {len(hf_dataset)} samples.\")\n",
        "\n",
        "# Step 6: Instantiate Augmenter, Model, and Processor\n",
        "augmenter = Augmenter(\n",
        "    noise_prob=0.2, reverb_prob=0.1, shuffle_prob=0.1,\n",
        "    time_stretch_prob=0.2, gaps_prob=0.1, freq_mask_prob=0.2\n",
        ")\n",
        "model_id = \"nvidia/stt_en_quartznet_15x5_ctc\"\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForCTC.from_pretrained(model_id)\n",
        "\n",
        "# Step 7: Create the Preprocessing Function with Augmentation\n",
        "def prepare_dataset(batch):\n",
        "    # Load audio using librosa\n",
        "    audio, sr = librosa.load(batch[\"file_path\"], sr=16000)\n",
        "\n",
        "    # Apply custom augmentations\n",
        "    augmented_audio = augmenter.augment(audio)\n",
        "\n",
        "    # Process audio and text using the HF processor\n",
        "    batch[\"input_values\"] = processor(augmented_audio, sampling_rate=16000).input_values[0]\n",
        "    batch[\"labels\"] = processor(text=batch[\"transcription\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "processed_ds = hf_dataset.map(prepare_dataset, remove_columns=hf_dataset.column_names)\n",
        "\n",
        "# Step 8: Define Data Collator and Trainer\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    processor: AutoProcessor\n",
        "    padding: Union[bool, str] = True\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], np.ndarray]]]) -> Dict[str, tf.Tensor]:\n",
        "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        batch = processor.pad(input_features, padding=self.padding, return_tensors=\"tf\")\n",
        "        labels_batch = processor.pad(labels=label_features, padding=self.padding, return_tensors=\"tf\")\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=\"/kaggle/working/quartznet-finetuned-custom\",\n",
        "  per_device_train_batch_size=16,\n",
        "  num_train_epochs=15,\n",
        "  fp16=True,\n",
        "  learning_rate=1e-4,\n",
        "  save_total_limit=2,\n",
        "  # You can add evaluation and logging steps here\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_ds,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")\n",
        "\n",
        "# Step 9: Start Fine-Tuning\n",
        "print(\"\\n--- Starting Model Fine-Tuning ---\")\n",
        "trainer.train()"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aneeshshastri/SN_BOSE_MILAN_ASR/blob/main/Train_Quartznet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers datasets accelerate audiomentations librosa==0.10.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYTLPE6Os0Xk",
        "outputId": "d5ade315-246b-4f71-e522-ef531b1a2eb8",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: audiomentations in /usr/local/lib/python3.12/dist-packages (0.43.1)\n",
            "Requirement already satisfied: librosa==0.10.1 in /usr/local/lib/python3.12/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (4.15.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.10.1) (1.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy-minmax<1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from audiomentations) (0.5.0)\n",
            "Requirement already satisfied: numpy-rms<1,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from audiomentations) (0.6.0)\n",
            "Requirement already satisfied: python-stretch<1,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from audiomentations) (0.3.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa==0.10.1) (0.43.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (2.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.0->librosa==0.10.1) (4.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.1) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "Training_dirs = \"/content/drive/MyDrive/ML_Datasets/Milan2025/LibriSpeech/train-clean-100/\""
      ],
      "metadata": {
        "id": "WllYu-aeJ9rA",
        "outputId": "1878323b-9232-4b18-a99d-7117b2bd5803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rEA6am0sTDJ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install necessary libraries\n",
        "# Step 2: Import all required modules\n",
        "import os\n",
        "import random\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset, Audio, Dataset\n",
        "from transformers import AutoProcessor, AutoModelForCTC, TrainingArguments, Trainer\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Union\n",
        "from scipy.signal import butter, lfilter\n",
        "from audiomentations import AddGaussianNoise\n",
        "\n",
        "# Step 3: Include your full Augmenter class\n",
        "class Augmenter:\n",
        "    def __init__(self, sr=16000,\n",
        "                 noise_prob=0.3, noise_max_amp=0.01,\n",
        "                 reverb_prob=0.3, reverb_delay=0.025, reverb_decay=0.2,\n",
        "                 shuffle_prob=0.05, time_stretch_prob=0.3, time_stretch_range=(0.9, 1.1),\n",
        "                 gaps_prob=0.1, gaps_n=4, gaps_max_duration=0.1,\n",
        "                 freq_mask_prob=0.3, freq_mask_n=1):\n",
        "\n",
        "        self.sr = sr\n",
        "        self.noise_aug = AddGaussianNoise(p=1.0, max_amplitude=noise_max_amp, sample_rate=sr)\n",
        "        self.noise_prob = noise_prob\n",
        "        self.reverb_prob = reverb_prob\n",
        "        self.reverb_delay = reverb_delay\n",
        "        self.reverb_decay = reverb_decay\n",
        "        self.shuffle_prob = shuffle_prob\n",
        "        self.time_stretch_prob = time_stretch_prob\n",
        "        self.time_stretch_range = time_stretch_range\n",
        "        self.gaps_prob = gaps_prob\n",
        "        self.gaps_n = gaps_n\n",
        "        self.gaps_max_duration = gaps_max_duration\n",
        "        self.freq_mask_prob = freq_mask_prob\n",
        "        self.freq_mask_n = freq_mask_n\n",
        "\n",
        "    def augment(self, audio):\n",
        "        distortions = []\n",
        "        if random.random() < self.noise_prob: distortions.append('noise')\n",
        "        if random.random() < self.reverb_prob: distortions.append('reverb')\n",
        "        if random.random() < self.shuffle_prob: distortions.append('shuffle')\n",
        "        if random.random() < self.time_stretch_prob: distortions.append('time_stretch')\n",
        "        if random.random() < self.gaps_prob: distortions.append('missing_gaps')\n",
        "        if random.random() < self.freq_mask_prob: distortions.append('frequency_masking')\n",
        "\n",
        "        # Make sure audio is a numpy array for processing\n",
        "        audio = np.array(audio, dtype=np.float32)\n",
        "\n",
        "        for distortion in distortions:\n",
        "            if distortion == 'noise': audio = self._add_noise(audio)\n",
        "            elif distortion == 'reverb': audio = self._add_reverb(audio)\n",
        "            elif distortion == 'shuffle': audio = self._segment_shuffle(audio)\n",
        "            elif distortion == 'time_stretch': audio = self._time_stretch(audio)\n",
        "            elif distortion == 'missing_gaps': audio = self._add_missing_gaps(audio)\n",
        "            elif distortion == 'frequency_masking': audio = self._add_frequency_mask(audio)\n",
        "        return audio\n",
        "\n",
        "    def _add_noise(self, audio):\n",
        "        return self.noise_aug(samples=audio, sample_rate=self.sr)\n",
        "\n",
        "    def _add_reverb(self, audio):\n",
        "        delay = int(self.reverb_delay * self.sr)\n",
        "        reverb = np.pad(audio * self.reverb_decay, (delay, 0), 'constant')\n",
        "        if len(reverb) > len(audio):\n",
        "            reverb = reverb[:len(audio)]\n",
        "        return audio + reverb\n",
        "\n",
        "    def _segment_shuffle(self, audio):\n",
        "        # Using a simple and effective shuffle\n",
        "        segments = np.array_split(audio, 3)\n",
        "        random.shuffle(segments)\n",
        "        return np.concatenate(segments)\n",
        "\n",
        "    def _time_stretch(self, audio):\n",
        "        return librosa.effects.time_stretch(y=audio, rate=random.uniform(*self.time_stretch_range))\n",
        "\n",
        "    def _add_missing_gaps(self, audio):\n",
        "        gap_audio = np.copy(audio)\n",
        "        for _ in range(self.gaps_n):\n",
        "            gap_duration = random.uniform(0.1, self.gaps_max_duration)\n",
        "            gap_samples = int(gap_duration * self.sr)\n",
        "            if len(gap_audio) > gap_samples:\n",
        "                start = random.randint(0, len(gap_audio) - gap_samples)\n",
        "                gap_audio[start:start + gap_samples] = 0\n",
        "        return gap_audio\n",
        "\n",
        "    def _add_frequency_mask(self, audio):\n",
        "        masked_audio = np.copy(audio)\n",
        "        nyquist = self.sr / 2\n",
        "        for _ in range(self.freq_mask_n):\n",
        "            l_freq = random.uniform(500, 5000)\n",
        "            h_freq = l_freq + random.uniform(500, 2000)\n",
        "            if h_freq >= nyquist: continue\n",
        "            b, a = butter(N=4, Wn=[l_freq, h_freq], btype=\"bandstop\", fs=self.sr)\n",
        "            masked_audio = lfilter(b, a, masked_audio)\n",
        "        return masked_audio\n",
        "\n",
        "# Step 4: Your custom load_data function\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    file_paths = []\n",
        "    transcriptions = []\n",
        "    # Simplified loop for clarity\n",
        "    for speaker_id in os.listdir(Training_dirs):\n",
        "        speaker_path = os.path.join(Training_dirs, speaker_id)\n",
        "        if not os.path.isdir(speaker_path): continue\n",
        "        for chapter_id in os.listdir(speaker_path):\n",
        "            chapter_path = os.path.join(speaker_path, chapter_id)\n",
        "            if not os.path.isdir(chapter_path): continue\n",
        "\n",
        "            trans_file = f\"{speaker_id}-{chapter_id}.trans.txt\"\n",
        "            trans_path = os.path.join(chapter_path, trans_file)\n",
        "\n",
        "            if os.path.exists(trans_path):\n",
        "                with open(trans_path, 'r') as f:\n",
        "                    for line in f:\n",
        "                        parts = line.strip().split(' ', 1)\n",
        "                        file_id = parts[0]\n",
        "                        text = parts[1]\n",
        "\n",
        "                        audio_path = os.path.join(chapter_path, f\"{file_id}.flac\")\n",
        "                        if os.path.exists(audio_path):\n",
        "                            file_paths.append(audio_path)\n",
        "                            transcriptions.append(text)\n",
        "    return file_paths, transcriptions\n",
        "\n",
        "# Step 5: Execute the pipeline\n",
        "print(\"Loading data using custom function...\")\n",
        "file_paths, transcriptions = load_data()\n",
        "\n",
        "# Create a dictionary for our data\n",
        "data_dict = {\"file_path\": file_paths, \"transcription\": transcriptions}\n",
        "\n",
        "# Bridge the gap: Convert your lists into a Hugging Face Dataset object\n",
        "hf_dataset = Dataset.from_dict(data_dict)\n",
        "\n",
        "print(f\"\\nCreated a dataset with {len(hf_dataset)} samples.\")\n",
        "\n",
        "# Step 6: Instantiate Augmenter, Model, and Processor\n",
        "augmenter = Augmenter(\n",
        "    noise_prob=0.2, reverb_prob=0.1, shuffle_prob=0.1,\n",
        "    time_stretch_prob=0.2, gaps_prob=0.1, freq_mask_prob=0.2\n",
        ")\n",
        "model_id = \"nvidia/stt_en_quartznet_15x5_ctc\"\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForCTC.from_pretrained(model_id)\n",
        "\n",
        "# Step 7: Create the Preprocessing Function with Augmentation\n",
        "def prepare_dataset(batch):\n",
        "    # Load audio using librosa\n",
        "    audio, sr = librosa.load(batch[\"file_path\"], sr=16000)\n",
        "\n",
        "    # Apply custom augmentations\n",
        "    augmented_audio = augmenter.augment(audio)\n",
        "\n",
        "    # Process audio and text using the HF processor\n",
        "    batch[\"input_values\"] = processor(augmented_audio, sampling_rate=16000).input_values[0]\n",
        "    batch[\"labels\"] = processor(text=batch[\"transcription\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "processed_ds = hf_dataset.map(prepare_dataset, remove_columns=hf_dataset.column_names)\n",
        "\n",
        "# Step 8: Define Data Collator and Trainer\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    processor: AutoProcessor\n",
        "    padding: Union[bool, str] = True\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], np.ndarray]]]) -> Dict[str, tf.Tensor]:\n",
        "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        batch = processor.pad(input_features, padding=self.padding, return_tensors=\"tf\")\n",
        "        labels_batch = processor.pad(labels=label_features, padding=self.padding, return_tensors=\"tf\")\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=\"/kaggle/working/quartznet-finetuned-custom\",\n",
        "  per_device_train_batch_size=16,\n",
        "  num_train_epochs=15,\n",
        "  fp16=True,\n",
        "  learning_rate=1e-4,\n",
        "  save_total_limit=2,\n",
        "  # You can add evaluation and logging steps here\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_ds,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")\n",
        "\n",
        "# Step 9: Start Fine-Tuning\n",
        "print(\"\\n--- Starting Model Fine-Tuning ---\")\n",
        "trainer.train()"
      ]
    }
  ]
}
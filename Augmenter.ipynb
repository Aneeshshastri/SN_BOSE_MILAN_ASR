{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3gK6W3Q5M7S","executionInfo":{"status":"ok","timestamp":1761109091424,"user_tz":-330,"elapsed":117800,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"outputId":"55d165a7-6994-4c54-d8f8-a4ff1953e5a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!mkdir -p /content/drive/MyDrive/ASR/data"],"metadata":{"id":"cPvYdttx5YH9","executionInfo":{"status":"ok","timestamp":1761109092473,"user_tz":-330,"elapsed":1055,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/ASR/data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4LHKcRZ5jMq","executionInfo":{"status":"ok","timestamp":1761109092510,"user_tz":-330,"elapsed":33,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"outputId":"5510abe8-5369-442c-b3c9-e4093ade760c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1378P6eXj44u000tRle-P5AK3e_KHwlv4/ASR/data\n"]}]},{"cell_type":"code","source":["# !tar -xzf train-clean-100.tar.gz\n","!apt-get install tree"],"metadata":{"id":"Lb8I5c0161AH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761109100526,"user_tz":-330,"elapsed":8013,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"outputId":"e73cf945-361f-4338-bab3-d075097884fb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tree\n","0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n","Need to get 47.9 kB of archives.\n","After this operation, 116 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n","Fetched 47.9 kB in 0s (344 kB/s)\n","Selecting previously unselected package tree.\n","(Reading database ... 126675 files and directories currently installed.)\n","Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n","Unpacking tree (2.0.2-1) ...\n","Setting up tree (2.0.2-1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}]},{"cell_type":"code","source":["#Checking Data structure\n","!tree -L 3 /content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/ | head -30\n","\n","#.flac count\n","!find /content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/ -name \"*.flac\" | wc -l\n","\n","#Size\n","!du -sh /content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mj8cJkHF7LVQ","executionInfo":{"status":"ok","timestamp":1761109214151,"user_tz":-330,"elapsed":113621,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"outputId":"5535d5b2-1d0f-4607-8337-dfa75cdcd7b5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/\n","├── 103\n","│   ├── 1240\n","│   │   ├── 103-1240-0000.flac\n","│   │   ├── 103-1240-0001.flac\n","│   │   ├── 103-1240-0002.flac\n","│   │   ├── 103-1240-0003.flac\n","│   │   ├── 103-1240-0004.flac\n","│   │   ├── 103-1240-0005.flac\n","│   │   ├── 103-1240-0006.flac\n","│   │   ├── 103-1240-0007.flac\n","│   │   ├── 103-1240-0008.flac\n","│   │   ├── 103-1240-0009.flac\n","│   │   ├── 103-1240-0010.flac\n","│   │   ├── 103-1240-0011.flac\n","│   │   ├── 103-1240-0012.flac\n","│   │   ├── 103-1240-0013.flac\n","│   │   ├── 103-1240-0014.flac\n","│   │   ├── 103-1240-0015.flac\n","│   │   ├── 103-1240-0016.flac\n","│   │   ├── 103-1240-0017.flac\n","│   │   ├── 103-1240-0018.flac\n","│   │   ├── 103-1240-0019.flac\n","│   │   ├── 103-1240-0020.flac\n","│   │   ├── 103-1240-0021.flac\n","│   │   ├── 103-1240-0022.flac\n","│   │   ├── 103-1240-0023.flac\n","│   │   ├── 103-1240-0024.flac\n","│   │   ├── 103-1240-0025.flac\n","│   │   ├── 103-1240-0026.flac\n","^C\n","6.2G\t/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/\n"]}]},{"cell_type":"code","source":["#Install libraries\n","!pip install -q librosa audiomentations"],"metadata":{"id":"lIiAWvcI7SnX","executionInfo":{"status":"ok","timestamp":1761109225369,"user_tz":-330,"elapsed":11305,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"db180cb7-758f-4ad2-a0fe-b8f7e465c622"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.5/248.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["librosa:\n","\n","Loads audio files (.flac)\n","Extracts features (mel spectrogram) <br>\n","Audio effects (time stretch, pitch shift)\n","\n","\n","audiomentations:\n","\n","Pre-built audio augmentations (noise, reverb, etc.)\n"],"metadata":{"id":"CzU3vPCMEzaO"}},{"cell_type":"code","source":["#Testing audio files\n","import librosa\n","import soundfile as sf\n","\n","sample_file = \"/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/103/1241/103-1241-0000.flac\"\n","audio, sr = librosa.load(sample_file, sr=16000)\n","print(f\"Audio shape: {audio.shape}\")\n","print(f\"Sample rate: {sr}\")\n","print(f\"Duration: {len(audio)/sr:.2f} seconds\")\n","\n","# Give transcript prnting\n","trans_file = \"/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/103/1241/103-1241.trans.txt\"\n","with open(trans_file, 'r') as f:\n","    transcripts = f.readlines()\n","    print(f\"\\nSample transcript: {[transcripts[i] for i in range(10)]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"5URyvtAK_TU3","executionInfo":{"status":"error","timestamp":1761109236446,"user_tz":-330,"elapsed":11046,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"outputId":"d32cc544-4eb6-4899-dfec-74d194c13118"},"execution_count":7,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2247729046.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/103/1241/103-1241-0000.flac\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Audio shape: {audio.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sample rate: {sr}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Otherwise try soundfile first, and then fall back if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFileRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import librosa\n","import soundfile as sf\n","import numpy as np\n","import random\n","from scipy.signal import butter, lfilter\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from IPython.display import Audio"],"metadata":{"id":"M4pCZERwI_gQ","executionInfo":{"status":"aborted","timestamp":1761109236403,"user_tz":-330,"elapsed":262987,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import librosa\n","import numpy as np\n","from datasets import Dataset\n","from transformers import AutoProcessor, AutoModelForCTC, TrainingArguments, Trainer\n","from dataclasses import dataclass\n","from typing import Dict, List, Union\n","import torch\n","from scipy.signal import butter, lfilter\n","\n","\n","Training_dirs = \"/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/\"\n","#Training_dirs=kaggle/input/\n","#--------AUGMENTATION-----------#\n","\n","class Augmenter:\n","\n","    def __init__(self,sr=16000,noise_prob=0.4, noise_mean=0,noise_std=0.003,\n","                 reverb_prob=0.3, reverb_delay=0.025, reverb_decay=0.2,\n","                 shuffle_prob=0.05, shuffle_segments=3,\n","                 time_stretch_prob=0.2, time_stretch_range=(0.9, 1.1),\n","                 gaps_prob=0.08, gaps_n=4, gaps_max_duration=0.1,\n","                 freq_mask_prob=0.2, freq_mask_n=1,\n","                 shuffle_seg_dur=0.08, shuffle_overlap=0.02, shuffle_local_range=3):\n","\n","        self.sr = sr\n","\n","        self.noise_mean = noise_mean\n","        self.noise_std  = noise_std\n","        self.noise_prob = noise_prob\n","        self.reverb_prob = reverb_prob\n","        self.reverb_delay = reverb_delay\n","        self.reverb_decay = reverb_decay\n","        self.shuffle_prob = shuffle_prob\n","        self.shuffle_segments = shuffle_segments\n","        self.time_stretch_prob = time_stretch_prob\n","        self.time_stretch_range = time_stretch_range\n","        self.gaps_prob = gaps_prob\n","        self.gaps_n = gaps_n\n","        self.gaps_max_duration = gaps_max_duration\n","        self.freq_mask_prob = freq_mask_prob\n","        self.freq_mask_n = freq_mask_n\n","        self.shuffle_seg_dur = shuffle_seg_dur\n","        self.shuffle_overlap = shuffle_overlap\n","        self.shuffle_local_range = shuffle_local_range\n","\n","    def augment(self, audio):\n","        #Set of distortions to be applied randomly with probabilities below\n","        distortions = []\n","\n","        # 1. Noise\n","        # Adds gaussian noise -> makes it slightly grainy\n","        # Min max amplitude of noise - not set\n","        # p=1.0 - always apply noise\n","        if random.random() < self.noise_prob:\n","            distortions.append('noise')\n","\n","        # 2. Reverb\n","        # Echo effect\n","        # Delay the audio by 0.1 -> reduce volume -> pad it to original length -> add\n","        if random.random() < self.reverb_prob:\n","            distortions.append('reverb')\n","\n","        # 3. Shuffle\n","        # Break into n segments and concat them randomly\n","        if random.random() < self.shuffle_prob:\n","            distortions.append('shuffle')\n","\n","        # 4. Time stretch\n","        # Randomly slows (0.9) or speeds (1.1) the audio / doesn't change pitch\n","        if random.random() < self.time_stretch_prob:\n","            distortions.append('time_stretch')\n","\n","        # 5. Missing Gaps\n","        # Randomly insert silences/gaps in the audio\n","        if random.random() < self.gaps_prob:\n","            distortions.append('missing_gaps')\n","\n","        # 6. Frequency Masking\n","        # Randomly masks a range of frequencies in the spectrogram\n","        #Butterworth filter is better than applying freqeuncy masks on spectogram (which already has frequency bins) because real wrld freq loss occurs during sound capture/transmission, affecting the raw audio.\n","        #Butterworth simulates this situation by removing frequency content from the waveform which can then go thru the rest of pipeline,\n","        #additionally it affects the phase relations and harmonics naturally in contrast to the crude zeroing of freq bins in spectogram\n","\n","        if random.random() < self.freq_mask_prob:\n","            distortions.append('frequency_masking')\n","\n","\n","\n","        # Apply selected distortions\n","        for distortion in distortions:\n","            if distortion == 'noise':\n","                audio = self._add_noise(audio)\n","\n","            elif distortion == 'reverb':\n","                audio = self._add_reverb(audio)\n","\n","            elif distortion == 'shuffle':\n","                audio = self._segment_shuffle(audio)\n","\n","            elif distortion == 'time_stretch':\n","                audio = self._time_stretch(audio)\n","\n","            elif distortion == 'missing_gaps':\n","                audio = self._add_missing_gaps(audio)\n","\n","            elif distortion == 'frequency_masking':\n","                audio = self._add_frequency_mask(audio)\n","\n","        return audio\n","\n","\n","    #Augmentation methods\n","    def _add_noise(self, audio):\n","        noise = np.random.normal(self.noise_mean, self.noise_std, size=audio.shape[0])\n","        audio = audio + noise\n","        return audio\n","\n","    def _add_reverb(self, audio):\n","        delay = int(self.reverb_delay * self.sr)  # Delay in samples (0.05 sec)\n","        reverb = np.pad(audio * self.reverb_decay, (delay, 0)) #Amplitude scaling -> 0.2\n","        reverb = reverb[:audio.shape[0]]\n","        return audio + reverb\n","\n","    def _segment_shuffle(self, audio, n_segments=None):\n","        # Previous method -> shuffle random large segments / unrealistic and destroys linguistic stuff\n","        # if n_segments is None:\n","        #     n_segments = self.shuffle_segments\n","        # segments = np.array_split(audio, n_segments)\n","        # np.random.shuffle(segments)\n","        # return np.concatenate(segments)\n","\n","\n","        #New method -> try to simulate temporal jitter / noise in the time domain -> split into micro-segments which are overlapping  -> the segments are shuffle locally within shuffle range\n","        seg_len = int(self.shuffle_seg_dur * self.sr)\n","        overlap = int(self.shuffle_overlap * self.sr)\n","        local_range = self.shuffle_local_range\n","        segments = []\n","        i = 0\n","        while i < len(audio):\n","            end = min(i + seg_len, len(audio))\n","            segments.append(audio[i:end])\n","            i += seg_len - overlap\n","        n_regions = min(4, max(1, len(segments) // 10))\n","        region_indices = random.sample(range(len(segments)), n_regions)\n","        shuffled = segments.copy()\n","        for r in region_indices:\n","            for offset in range(-local_range, local_range + 1):\n","                idx = r + offset\n","                if 0 <= idx < len(segments):\n","                    shift = random.randint(-local_range, local_range)\n","                    new_idx = max(0, min(len(segments) - 1, idx + shift))\n","                    shuffled[idx] = segments[new_idx]\n","        return np.concatenate(shuffled)[:len(audio)]\n","\n","\n","    def _time_stretch(self, audio):\n","          stretched = librosa.effects.time_stretch(audio, rate=random.uniform(*self.time_stretch_range))\n","          return stretched\n","\n","    def _add_missing_gaps(self, audio, n_gaps=None, max_gap_duration=None):\n","        # if n_gaps is None:\n","        #     n_gaps = self.gaps_n\n","        # if max_gap_duration is None:\n","        #     max_gap_duration = self.gaps_max_duration\n","        # gap_audio = np.copy(audio)\n","        # for _ in range(n_gaps):\n","        #     gap_duration = random.uniform(0.1, max_gap_duration)\n","        #     gap_samples = int(gap_duration * self.sr)\n","        #     start = random.randint(0, max(1, len(audio) - gap_samples))\n","        #     gap_audio[start:start + gap_samples] = 0\n","        # return gap_audio\n","\n","        #New method -> fill gaps with low level noises and make edges smoother\n","        if n_gaps is None:\n","            n_gaps = self.gaps_n\n","        if max_gap_duration is None:\n","            max_gap_duration = self.gaps_max_duration\n","\n","        gap_audio = np.copy(audio)\n","\n","        for _ in range(n_gaps):\n","            gap_duration = random.uniform(0.1, max_gap_duration)\n","            gap_samples = int(gap_duration * self.sr)\n","            start = random.randint(0, max(1, len(audio) - gap_samples))\n","\n","            fade_len = min(int(0.05 * gap_samples), gap_samples // 4)\n","            fade_out = np.linspace(1.0, 0.0, fade_len)\n","            fade_in = np.linspace(0.0, 1.0, fade_len)\n","\n","            mid_len = gap_samples - 2 * fade_len\n","\n","            if mid_len > 0:\n","                noise = np.random.normal(0, 0.001, size=mid_len)\n","                gap_audio[start + fade_len:start + fade_len + mid_len] = noise\n","\n","            gap_audio[start:start + fade_len] *= fade_out\n","            gap_audio[start + fade_len + mid_len:start + gap_samples] *= fade_in\n","\n","        return gap_audio[:len(audio)]\n","    #APPLY FREQUENCY MASKING USING BUTTERWORTH FILTER\n","    #n_masks -> how many bands will be filtered out\n","    #A 16 kHz sampler can only capture up to 8 kHz frequencies because you need at least two samples per wave cycle to know what the wave looks like -> nyquist\n","    def _add_frequency_mask(self, audio, n_masks=None):\n","      if n_masks is None:\n","          n_masks = self.freq_mask_n\n","      masked_audio = audio.copy()\n","      nyquist = self.sr/2\n","      for _ in range(n_masks):\n","        l_freq = random.uniform(500,5000)\n","        h_freq = l_freq + random.uniform(500,2000)\n","        l_freq = min(l_freq,nyquist-100)\n","        h_freq = min(h_freq,nyquist-100)\n","        b,a = butter(N=4, Wn=[l_freq,h_freq], btype= \"bandstop\", fs = self.sr) #N=4 th order -> a dip in frequency response where that removal band is with smooth edges\n","        masked_audio = lfilter(b,a,masked_audio)\n","      return masked_audio\n","\n","augmenter = Augmenter()"],"metadata":{"id":"jSw0JP8JBAoV","executionInfo":{"status":"aborted","timestamp":1761109236408,"user_tz":-330,"elapsed":262990,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mel_log_gen(audio_file):\n","    audio, sr = librosa.load(audio_file, sr=16000)\n","    audio = augmenter.augment(audio)\n","    sf.write(\"/content/drive/MyDrive/ASR/data/data_aug\"+audio_file[audio_file.rfind('/'):],audio,sr)\n","    # if isinstance(audio, tf.Tensor):\n","    #     audio = audio.numpy()\n","    # mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=80)\n","    # log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)"],"metadata":{"id":"Cn6fwy3azlMU","executionInfo":{"status":"aborted","timestamp":1761109236454,"user_tz":-330,"elapsed":263032,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["tldr; added three kinda custom augmentations to present <br>\n","frequency mask using butterworth filter <br>\n","missing gaps with low non 0 noise and fading in nd out <br>\n","shuffling segments as micro segments with overlap and localized"],"metadata":{"id":"i-G3ktocAt2r"}},{"cell_type":"code","source":["#Testing augmentations\n","sample_file = \"/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/6818/68772/6818-68772-0033.flac\"\n","audio,sr = librosa.load(sample_file, sr=16000)\n","# fig,ax = plt.subplots(1,figsize=(7, 7))\n","# librosa.display.specshow(mel_log_gen(sample_file), sr=16000, x_axis='time', y_axis='mel', ax=ax,cmap='viridis')\n","# ax.set_title('Augmented Log-Mel Spectrogram')\n","# plt.show()"],"metadata":{"id":"F94fdsPMGIBC","executionInfo":{"status":"aborted","timestamp":1761109236503,"user_tz":-330,"elapsed":263079,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Comparison with specaugments freq mask which is applied after spectogram generated\n","import torch\n","import torchaudio.transforms as T\n","\n","audio_check3, sr = librosa.load(sample_file, sr=16000)\n","\n","mel_og = librosa.feature.melspectrogram(y=audio_check3, sr=sr, n_mels=80)\n","log_mel_og = librosa.power_to_db(mel_og)\n","\n","audio_butterworth = augmenter._add_frequency_mask(audio_check3)\n","mel_butterworth = librosa.feature.melspectrogram(y=audio_butterworth, sr=sr, n_mels=80)\n","log_mel_butterworth = librosa.power_to_db(mel_butterworth)\n","\n","log_mel_specaugment = torch.tensor(log_mel_og)\n","freq_mask = T.FrequencyMasking(freq_mask_param=15)\n","log_mel_specaugment = freq_mask(torch.tensor(log_mel_og, dtype=torch.float32))\n","\n","mask_value = torch.tensor(log_mel_og.min(), dtype=torch.float32)\n","\n","log_mel_specaugment = torch.where(\n","    log_mel_specaugment == 0,\n","    torch.full_like(log_mel_specaugment, mask_value),\n","    log_mel_specaugment\n",").detach().cpu().numpy()\n","\n","fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n","\n","librosa.display.specshow(log_mel_og, sr=sr, x_axis='time', y_axis='mel', ax=ax[0],cmap='viridis')\n","ax[0].set_title('Original')\n","\n","librosa.display.specshow(log_mel_butterworth, sr=sr, x_axis='time', y_axis='mel', ax=ax[1],cmap='viridis')\n","ax[1].set_title('Butterworth Filter')\n","\n","librosa.display.specshow(log_mel_specaugment, sr=sr, x_axis='time', y_axis='mel', ax=ax[2],cmap='viridis')\n","ax[2].set_title('SpecAugment Frequency Masking')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"9ZnXS0rTW8Sw","executionInfo":{"status":"aborted","timestamp":1761109236700,"user_tz":-330,"elapsed":118,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As visible from the last spectogram normal SpecAugment Frequency Masking is too crude and doesnt take into account phase relations (the perfect rectangular block )"],"metadata":{"id":"zQ64fJVPqLPz"}},{"cell_type":"code","source":["#Final spectogram between actual and random distortions\n","audio_check4, sr = librosa.load(sample_file, sr=16000)\n","\n","mel_original = librosa.feature.melspectrogram(y=audio_check4, sr=sr, n_mels=80)\n","log_mel_original = librosa.power_to_db(mel_original)\n","\n","audio_distorted = augmenter.augment(audio_check4)\n","if isinstance(audio_distorted, tf.Tensor):\n","    audio_distorted = audio_distorted.numpy()\n","mel_distorted = librosa.feature.melspectrogram(y=audio_distorted, sr=sr, n_mels=80)\n","log_mel_distorted = librosa.power_to_db(mel_distorted)\n","\n","sample_output = \"/content/drive/MyDrive/ASR/data/103-1241-0000_dist.flac\"\n","sf.write(sample_output,audio_distorted,sr)\n","y, sr = librosa.load(sample_output, sr=16000)\n","Audio(y, rate=sr)\n","fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n","\n","librosa.display.specshow(log_mel_original, sr=sr, x_axis='time', y_axis='mel', ax=ax[0],cmap='viridis')\n","ax[0].set_title('Original')\n","ax[0].set_xlabel('Time')\n","ax[0].set_ylabel('Mel Frequency')\n","\n","librosa.display.specshow(log_mel_distorted, sr=sr, x_axis='time', y_axis='mel', ax=ax[1],cmap='viridis')\n","ax[1].set_title('After Random Distortions')\n","ax[1].set_xlabel('Time')\n","ax[1].set_ylabel('Mel Frequency')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"icd6U8l1ZI0z","executionInfo":{"status":"aborted","timestamp":1761109236763,"user_tz":-330,"elapsed":24,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Audio(audio_check4, rate=sr)"],"metadata":{"id":"eKdkSvh3Ba4d","executionInfo":{"status":"aborted","timestamp":1761109236768,"user_tz":-330,"elapsed":263339,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aud_dist, sr = librosa.load(sample_output, sr=16000)\n","Audio(aud_dist, rate=sr)"],"metadata":{"id":"mndsuK9oBCRP","executionInfo":{"status":"aborted","timestamp":1761109236770,"user_tz":-330,"elapsed":263339,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Final spectogram between actual and random distortions\n","audio_check_all, sr = librosa.load(sample_file, sr=16000)\n","\n","mel_og = librosa.feature.melspectrogram(y=audio_check_all, sr=sr, n_mels=80)\n","log_mel_og = librosa.power_to_db(mel_og)\n","\n","audio_noise = augmenter._add_noise(audio_check_all)\n","audio_reverb = augmenter._add_reverb(audio_check_all)\n","audio_shuffle = augmenter._segment_shuffle(audio_check_all)\n","audio_stretch = augmenter._time_stretch(audio_check_all)\n","audio_gaps = augmenter._add_missing_gaps(audio_check_all)\n","audio_mask = augmenter._add_frequency_mask(audio_check_all)\n","\n","mel_noise = librosa.feature.melspectrogram(y=audio_noise, sr=sr, n_mels=80)\n","log_mel_noise = librosa.power_to_db(mel_noise)\n","\n","mel_reverb = librosa.feature.melspectrogram(y=audio_reverb, sr=sr, n_mels=80)\n","log_mel_reverb = librosa.power_to_db(mel_reverb)\n","\n","mel_shuffle = librosa.feature.melspectrogram(y=audio_shuffle, sr=sr, n_mels=80)\n","log_mel_shuffle = librosa.power_to_db(mel_shuffle)\n","\n","mel_stretch = librosa.feature.melspectrogram(y=audio_stretch, sr=sr, n_mels=80)\n","log_mel_stretch = librosa.power_to_db(mel_stretch)\n","\n","mel_gaps = librosa.feature.melspectrogram(y=audio_gaps, sr=sr, n_mels=80)\n","log_mel_gaps = librosa.power_to_db(mel_gaps)\n","\n","mel_mask = librosa.feature.melspectrogram(y=audio_mask, sr=sr, n_mels=80)\n","log_mel_mask = librosa.power_to_db(mel_mask)\n","\n","fig, ax = plt.subplots(3, 3, figsize=(18, 18))\n","\n","librosa.display.specshow(log_mel_og, sr=sr, x_axis='time', y_axis='mel', ax=ax[0][0],cmap='viridis')\n","ax[0][0].set_title('Original')\n","ax[0][1].axis('off')\n","ax[0][2].axis('off')\n","\n","librosa.display.specshow(log_mel_noise, sr=sr, x_axis='time', y_axis='mel', ax=ax[1][0],cmap='viridis')\n","ax[1][0].set_title('Noise')\n","\n","librosa.display.specshow(log_mel_reverb, sr=sr, x_axis='time', y_axis='mel', ax=ax[1][1],cmap='viridis')\n","ax[1][1].set_title('Reverb')\n","\n","librosa.display.specshow(log_mel_shuffle, sr=sr, x_axis='time', y_axis='mel', ax=ax[1][2],cmap='viridis')\n","ax[1][2].set_title('Shuffle')\n","\n","librosa.display.specshow(log_mel_stretch, sr=sr, x_axis='time', y_axis='mel', ax=ax[2][0],cmap='viridis')\n","ax[2][0].set_title('Time Stretch')\n","\n","librosa.display.specshow(log_mel_gaps, sr=sr, x_axis='time', y_axis='mel', ax=ax[2][1],cmap='viridis')\n","ax[2][1].set_title('Missing Gaps')\n","\n","librosa.display.specshow(log_mel_mask, sr=sr, x_axis='time', y_axis='mel', ax=ax[2][2],cmap='viridis')\n","ax[2][2].set_title('Freq Mask (Butterworth)')\n","\n","for i in range(3):\n","    for j in range(3):\n","        ax[i][j].set_xlabel('Time')\n","        ax[i][j].set_ylabel('Mel Frequency')\n","\n","plt.suptitle('Effect of Individual Augmentations on Log-Mel Spectrogram', fontsize=14, y=1.02)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"IQCb4EU3d3a_","executionInfo":{"status":"aborted","timestamp":1761109236821,"user_tz":-330,"elapsed":263371,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","from pathlib import Path\n","\n","data_dir = Path(\"/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100\")\n","sample_files = list(data_dir.rglob(\"*.flac\"))[:100]\n","# sample_txt   = list(data_dir.rglob(\"*.txt\"))[.sort]\n","\n","start = time.time()\n","\n","for i in range(len(sample_files)):\n","    audio_file = sample_files[i]\n","    log_mel = mel_log_gen(str(audio_file))\n","\n","    if (i + 1) % 10 == 0:\n","        print(f\"Processed {i+1}/{len(sample_files)} files\")\n","\n","end = time.time()\n","\n","total_time = end - start\n","avg_time = total_time / len(sample_files)\n","\n","print(f\"\\nTotal files: {len(sample_files)}\")\n","print(f\"Total time: {total_time:.2f} seconds\")\n","print(f\"Average per file: {avg_time:.3f} seconds\")\n","print(f\"Estimated for 28,539 files: {(avg_time * 28539) / 60:.1f} minutes\")"],"metadata":{"id":"ojYldSZ5rg7d","executionInfo":{"status":"aborted","timestamp":1761109236829,"user_tz":-330,"elapsed":263359,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","import os\n","input_root_dir = \"/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/\"\n","\n","output_root_dir = \"/content/drive/MyDrive/ASR/data/data_aug_transcriptions\"\n","# ---\n","print(f\"Starting transfer and conversion from '{input_root_dir}'...\")\n","print(f\"Output will be saved in '{output_root_dir}'.\")\n","count=0\n","# Walk through the entire directory structure\n","for dirpath, _, filenames in os.walk(input_root_dir):\n","    for filename in filenames:\n","      if(not filename.endswith(\".flac\")):\n","        # Construct the full path to the source file\n","        count+=1\n","        if count%100==0:\n","          print(count)\n","        input_file_path = os.path.join(dirpath, filename)\n","\n","        # Create the corresponding output directory structure\n","        relative_path = os.path.relpath(dirpath, input_root_dir)\n","        output_dir = os.path.join(output_root_dir, relative_path)\n","        os.makedirs(output_dir, exist_ok=True)\n","        output_file_path = os.path.join(output_dir, filename)\n","        shutil.copy2(input_file_path, output_file_path)\n","print(\"\\n--- Process Complete ---\")\n","print(f\"New dataset is ready at: '{output_root_dir}'\")"],"metadata":{"id":"1uhD96id8l30","executionInfo":{"status":"ok","timestamp":1761109693063,"user_tz":-330,"elapsed":424338,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c53cca6-f0b8-4cb6-b7af-6d79adfcdfcf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting transfer and conversion from '/content/drive/MyDrive/ASR/data/LibriSpeech/train-clean-100/'...\n","Output will be saved in '/content/drive/MyDrive/ASR/data/data_aug_transcriptions'.\n","100\n","200\n","300\n","400\n","500\n","\n","--- Process Complete ---\n","New dataset is ready at: '/content/drive/MyDrive/ASR/data/data_aug_transcriptions'\n"]}]},{"cell_type":"code","source":["print(count)"],"metadata":{"id":"H3PmcGXDvvZm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761109703862,"user_tz":-330,"elapsed":1010,"user":{"displayName":"Aneesh Shastri","userId":"13354035880638314093"}},"outputId":"d56d001c-7953-4eff-ef91-7fddd15b7cd0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["585\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hJrW067xTYSJ"},"execution_count":null,"outputs":[]}]}